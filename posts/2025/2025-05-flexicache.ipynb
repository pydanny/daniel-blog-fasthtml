{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885d07f9",
   "metadata": {},
   "source": [
    "---\n",
    "date: \"2025-05-01T08:20:00.00Z\"\n",
    "title: \"Exploring flexicache\"\n",
    "description: \"An exploration of using flexicache for caching in Python.\"\n",
    "published: false\n",
    "tags:\n",
    "  - python\n",
    "  - fastcore\n",
    "  - answerdotai\n",
    "time_to_read: 2\n",
    "type: post\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6037755",
   "metadata": {},
   "source": [
    "When coding in Python I find I really like to use decorators to cache results from functions and methods, often to memory and sometimes to ephemeral stores like memcached. In fact, I've worked on and created several cache decorators, including on that influenced the implementation of the `@cached_property` decorator in Python 3.8. \n",
    "\n",
    "A cache decorator called [flexicache](https://fastcore.fast.ai/xtras.html#flexicache) is part of the [fastcore](https://pypi.org/project/fastcore/) library. `flexicache` allows you to cache in memory results from functions and methods in a flexible way. Each use of the decorator is configured to use one or more cache invalidation policies. \n",
    "\n",
    "Two policies, `time_policy` and `mtime_policy` are used to invalidate the cache based on time and file modification time respectively. The `time_policy` invalidates the cache after a specified number of seconds, while the `mtime_policy` invalidates the cache if the file has been modified since the last time it was cached.\n",
    "\n",
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe2ee8",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c73ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from fastcore.xtras import flexicache, time_policy, mtime_policy\n",
    "# Libraries used in testing cache validity and cache invalidation\n",
    "from random import randint\n",
    "from pathlib import Path\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70758f7",
   "metadata": {},
   "source": [
    "Here's a simple function returning a number between 1 to 1000 that we can show being cached. We'll use this in all our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f606e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_func():\n",
    "    return randint(1, 1000)\n",
    "\n",
    "# Assert False as the function is not cached\n",
    "assert random_func() != random_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c74eab",
   "metadata": {},
   "source": [
    "### Time policy\n",
    "\n",
    "This is how we use the `time_policy` to cache the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01de4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "@flexicache(time_policy(.1))\n",
    "def random_func():\n",
    "    return randint(1, 1000) \n",
    "\n",
    "# True as the function is cached\n",
    "assert random_func() == random_func()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c047181",
   "metadata": {},
   "source": [
    "Let's use the sleep function to simulate time between calls to `random_func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a90b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = random_func()\n",
    "assert result == random_func()  # True as the function is cached \n",
    "# Sleep for .2 seconds to allow cache to expire\n",
    "sleep(0.2)  \n",
    "# False as the cache has expired and the function is called again\n",
    "assert result != random_func()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a01db",
   "metadata": {},
   "source": [
    "### File modification time (mtime_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e3f72",
   "metadata": {},
   "source": [
    "We'll try the `mtime_policy` policy, checking to see if touching a file invalidates the cache. We'll use this site's `main.py` file as the file to touch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d971cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@flexicache(mtime_policy('../../main.py'))\n",
    "def random_func():\n",
    "    return randint(1, 1000)\n",
    "\n",
    "# True as the function is cached\n",
    "assert random_func() == random_func()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea618d8e",
   "metadata": {},
   "source": [
    "Now let's use the Path.touch() method to touch the file. This will update the file's modification time to the current time, which should invalidate the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75fd86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to cache the result\n",
    "result = random_func() \n",
    "assert result == random_func()  # True as the function is cached \n",
    "# Update the file's modification time, which invalidates the cache\n",
    "Path('../../main.py').touch()  \n",
    "# Assert False as the cache is invalidated\n",
    "assert result != random_func()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc263ccf",
   "metadata": {},
   "source": [
    "## Using multiple policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0c3ce",
   "metadata": {},
   "source": [
    "A unique feature of `flexicache` is that you can use multiple policies at the same time. This allows you to combine the benefits of different caching strategies.\n",
    "In this example, we'll use both the `time_policy` and `mtime_policy` policies together. This means that the cache will be invalidated if either the time limit is reached or the file has been modified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812716d",
   "metadata": {},
   "source": [
    "Testing the cache with both policies is identical to the previous examples. We'll call the function, first with the time policy, then with the mtime policy, and finally with both policies. We'll also touch the file to see if it invalidates the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e319ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@flexicache(time_policy(.1), mtime_policy('../../main.py'))\n",
    "def random_func():\n",
    "    return randint(1, 1000)\n",
    "\n",
    "# True as the function is cached\n",
    "assert random_func() == random_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318606df",
   "metadata": {},
   "source": [
    "Testing time invalidation is the same as before. We'll call the function, wait for the time limit to be reached, and then call it again to see if the cache is invalidated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28c78322",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = random_func()\n",
    "assert result == random_func()  # True as the function is cached \n",
    "# Sleep for .2 seconds to allow cache to expire\n",
    "sleep(0.2)  \n",
    "# False as the cache has expired and the function is called again\n",
    "assert result != random_func() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a92dd",
   "metadata": {},
   "source": [
    "Testing file timestamp is the same as before. We'll call the function, touch the file, and then call it again to see if the cache is invalidated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb53d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to cache the result\n",
    "result = random_func() \n",
    "assert result == random_func()  # True as the function is cached \n",
    "# Update the file's modification time, which invalidates the cache\n",
    "Path('../../main.py').touch()  \n",
    "# Assert False as the cache is invalidated\n",
    "assert result != random_func()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d40bd",
   "metadata": {},
   "source": [
    "## timed_cache convenience wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50573750",
   "metadata": {},
   "source": [
    "`lru_cache` is a built-in Python decorator that provides a simple way to cache the results of a function. It uses a Least Recently Used (LRU) caching strategy, which means that it keeps track of the most recently used items as based on arguments and removes the least recently used items when the cache reaches its maximum size. In other words, it takes out the latest items from the cache first when it runs out of space.\n",
    "\n",
    "The downside is that it doesn't have a timeout feature, so if you want to cache results for a specific amount of time, you need to implement that yourself.\n",
    "\n",
    "`fastcore.xtras.timed_cache` is an implementation of `flexicache` that adds a timeout feature to `functools.lru_cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73228e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.xtras import timed_cache\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=2)\n",
    "def random_func(v): # lru_cache uses arguments to set the cache key\n",
    "    return randint(1, 1000)\n",
    "\n",
    "# True as the function is cached\n",
    "assert random_func(1) == random_func(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cd1ca",
   "metadata": {},
   "source": [
    "Testing the timeout is the same as before with `flexicache(time_policy(.1))`. We'll call the function, wait for the timeout to be reached, and then call it again to see if the cache is invalidated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c22184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to cache the result\n",
    "result1 = random_func(1) \n",
    "assert result1 == random_func(1)  # True as the function is cached \n",
    "# Wait long enough for the cache to expire\n",
    "sleep(0.2)\n",
    "# Assert False as the cache is time invalidated\n",
    "# assert result1 != random_func(1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test out the `timed_cache` decorator to see how it behaves as an `lru_cache` replacement. Remember, it has a maxsize of 2, meaning after 2 saves it starts discarding the oldest cache entries. We'll call the function with different arguments to see how it behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b0fb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = random_func(1) \n",
    "assert result1 == random_func(1) # True as the function is cached\n",
    "assert random_func(2) == random_func(2)  # True as the function is cached\n",
    "assert random_func(3) == random_func(3)  # True as the function is cached\n",
    "assert result1 != random_func(1) # False as the function is no longer cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
